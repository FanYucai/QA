{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "print(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##!/usr/bin/env python\n",
    "## coding=utf-8\n",
    "import jieba\n",
    "\n",
    "filePath=u'corpus_news.txt'\n",
    "fileSegWordDonePath =u'corpusSegDone_news.txt'\n",
    "# read the file by line\n",
    "fileTrainRead = []\n",
    "#fileTestRead = []\n",
    "with open(filePath, encoding='UTF-8') as fileTrainRaw:\n",
    "    for line in fileTrainRaw:\n",
    "        fileTrainRead.append(line)\n",
    "\n",
    "# define this function to print a list with Chinese\n",
    "def PrintListChinese(list):\n",
    "    for i in range(len(list)):\n",
    "        print(list[i])\n",
    "        \n",
    "# segment word with jieba\n",
    "fileTrainSeg=[]\n",
    "for i in range(len(fileTrainRead)):\n",
    "    fileTrainSeg.append([' '.join(list(jieba.cut(fileTrainRead[i][9:-11],cut_all=False)))])\n",
    "    if i % 10000 == 0 :\n",
    "        print(i)\n",
    "        \n",
    "# save the result\n",
    "with open(fileSegWordDonePath,'wb') as fW:\n",
    "    for i in range(len(fileTrainSeg)):\n",
    "        fW.write(fileTrainSeg[i][0].encode('utf-8'))\n",
    "        fW.write('\\n'.encode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "sentences=word2vec.Text8Corpus(u'corpusSegDone_news.txt')\n",
    "model=word2vec.Word2Vec(sentences, size=50)\n",
    "model.save(\"model_news_50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "#=================================================\n",
    "# No.1\n",
    "#=================================================\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "model = gensim.models.Word2Vec.load(\"model_news\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18494\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "df_cut = pd.DataFrame()\n",
    "filepath = r'data\\develop.data'\n",
    "dataheader = ['Q', 'A', '?']\n",
    "df = pd.read_csv(filepath, sep='\\t', names=dataheader)\n",
    "print(df.shape[0])\n",
    "\n",
    "for row in df.itertuples():\n",
    "    strQ = \" \".join(jieba.cut(row[1]))\n",
    "#     segments = pseg.cut(row[1], HMM=True)     \n",
    "    strA = \" \".join(jieba.cut(row[2]))\n",
    "#     segments = pseg.cut(row[2], HMM=True)\n",
    "    new = pd.DataFrame({\"Q\":strQ, \"A\":strA, \"?\":row[3]}, index=[\"0\"])\n",
    "    df_cut = df_cut.append(new, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18494\n",
      "158504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=================================================\n",
    "# No.2\n",
    "#=================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import jieba \n",
    "\n",
    "def ReLU(x):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def MyModel(q):\n",
    "# 把词的列表映射到一个句子的向量\n",
    "    s = np.zeros((1, d))\n",
    "    for i in q :\n",
    "        try:\n",
    "            if i.isdigit():\n",
    "                c = model[\"１\"]\n",
    "            elif i.isalpha():\n",
    "                c = model[\"Ｅ\"]\n",
    "#             elif i.isalnum():\n",
    "#                 c = model[\"\"]\n",
    "            else:\n",
    "                c = model[i]\n",
    "            \n",
    "        except KeyError:\n",
    "#             print(\"not in vocabulary: \" + i)\n",
    "            c = 0\n",
    "        s += c\n",
    "    if LA.norm(s) != 0:\n",
    "        s = s/LA.norm(s)\n",
    "    return s\n",
    "\n",
    "dev_filepath = r'data\\develop.data'\n",
    "train_filepath = r'data\\training.data'\n",
    "dataheader = ['Q', 'A', '?']\n",
    "df_dev = pd.read_csv(dev_filepath, sep='\\t', names=dataheader)\n",
    "df_train = pd.read_csv(train_filepath, sep='\\t', names=dataheader)\n",
    "print(df_dev.shape[0])\n",
    "print(df_train.shape[0])\n",
    "\n",
    "N = df_train.shape[0]\n",
    "d = 200\n",
    "Qvecset = list()\n",
    "Avecset = list()\n",
    "X = list()\n",
    "y = list()\n",
    "Xtest = list()\n",
    "ytest = list()\n",
    "# Get q, a, y and their numbers \n",
    "\n",
    "cnt = 0\n",
    "for row in df_train.head(1000).itertuples():\n",
    "    cnt += 1\n",
    "    segq = jieba.cut(row[1])\n",
    "    sega = jieba.cut(row[2])\n",
    "    if row[3] == 0:\n",
    "        if cnt >= 30:\n",
    "            X.append((np.concatenate((MyModel(sega), MyModel(segq)), axis=1)).reshape(-1).tolist())\n",
    "            y.append(row[3])\n",
    "            cnt = 0\n",
    "        else:\n",
    "            cnt += 1\n",
    "    elif row[3] == 1:\n",
    "        X.append((np.concatenate((MyModel(sega), MyModel(segq)), axis=1)).reshape(-1).tolist())\n",
    "        y.append(row[3])\n",
    "\n",
    "for row in df_dev.head(100).itertuples():\n",
    "    segq = jieba.cut(row[1])\n",
    "    sega = jieba.cut(row[2])\n",
    "    Xtest.append((np.concatenate((MyModel(sega), MyModel(segq)), axis=1)).reshape(-1).tolist())\n",
    "    ytest.append(row[3])\n",
    "    \n",
    "# Transformation Matrix\n",
    "M = 0.01 * np.random.randn(d,d)\n",
    "b = np.zeros((1,d))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716843028421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab\n",
    "# len(model.wv.vocab)\n",
    "# print(model.most_similar(u\"１\"))\n",
    "# print(model.most_similar(u\"Ｍ\")) \n",
    "# print(model.most_similar(u\"Ｍ\")) \n",
    "# print(model.most_similar(u\"Ｍ\")) \n",
    "# print(model.most_similar(u\"Ｅ\")) \n",
    "# print(model.most_similar(u\"Ａ\")) \n",
    "# print(model.most_similar(u\"Ｂ\")) \n",
    "print(model.similarity(u\"嘻哈\", u\"摇滚\"))\n",
    "# print(model[\"扫帚\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10148562  0.10050879  0.09977845  0.09964666  0.09988423  0.1015948\n",
      "  0.0996053   0.09957002  0.09971342  0.09986899  0.09960834  0.09990114\n",
      "  0.10065254  0.1008908   0.10037613  0.0998111   0.09961408  0.10029382\n",
      "  0.10071162  0.09980456  0.0996296   0.09964748  0.10003668  0.10013549\n",
      "  0.10117299  0.09985102  0.09985594  0.10051199  0.09966539  0.09968952\n",
      "  0.09980826  0.09993674  0.09962871  0.10020328  0.0996372   0.0996372\n",
      "  0.09967469  0.09991043  0.09987741  0.099628    0.09970219  0.09967322\n",
      "  0.09972049  0.09972242  0.10009735  0.09942591  0.09995224  0.099804\n",
      "  0.09963126  0.09958807  0.09978981  0.0996274   0.09964399  0.09960914\n",
      "  0.10046244  0.10119863  0.09972139  0.10133881  0.09968817  0.09995254\n",
      "  0.09976153  0.10055964  0.10008632  0.10055964  0.10013398  0.09966115\n",
      "  0.09962817  0.10057458  0.09965906  0.10005232  0.10176949  0.09965196\n",
      "  0.0997598   0.09982904  0.09994992  0.1000275   0.09972867  0.09966965\n",
      "  0.09965545  0.09990205  0.09966201  0.09964688  0.09960142  0.10036073\n",
      "  0.09962812  0.10008349  0.09991102  0.0998765   0.10056027  0.09967025\n",
      "  0.09964601  0.10047771  0.09993831  0.10029923  0.10014505  0.0999277\n",
      "  0.09963822  0.09976564  0.0996421   0.09958927  0.09983036  0.09973629\n",
      "  0.09980406  0.10007256  0.10020854  0.09963847  0.0996191   0.09969864\n",
      "  0.09971502  0.09958444  0.09962639  0.09976308  0.09998897  0.09958927]\n",
      "[1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#=================================================\n",
    "# No.3\n",
    "#=================================================\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "# X = [[1,2], [2,3], [3,4], [4,5], [5,6]]\n",
    "# y = [1, 1, 0, 0, 0]\n",
    "# clf = linear_model.LogisticRegression(penalty='l2')\n",
    "clf = SVR()\n",
    "clf.fit(X, y)\n",
    "print(clf.predict(X))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
